{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoAckHSdsNb6",
        "outputId": "6a72474d-75cd-4733-f83e-c9250220a658"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "import warnings\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "from pyjarowinkler import distance as jw_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG5g-2r5sQnP"
      },
      "source": [
        "1. Creating the training and testing learning curves over epoch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "Bjdc_OvxsjYy",
        "outputId": "4a956792-fb96-4098-b641-eb6dc633bd79"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '__pycache__/train/0'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_5378/1033232814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mtest_f_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mtrain_csv_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mtest_csv_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '__pycache__/train/0'"
          ]
        }
      ],
      "source": [
        "dir_name_list = glob.glob(\"results\")\n",
        "\n",
        "for dir_name in dir_name_list:\n",
        "  train_dir = os.path.join(dir_name, \"train\")\n",
        "  test_dir = os.path.join(dir_name, \"val\")\n",
        "\n",
        "  epoch_numbers = list()\n",
        "  train_f_scores = list()\n",
        "  test_f_scores = list()\n",
        "\n",
        "  train_csv_list = [f for f in os.listdir(os.path.join(train_dir, str(0))) if os.path.isfile(os.path.join(train_dir, str(0), f))]\n",
        "  test_csv_list = [f for f in os.listdir(os.path.join(train_dir, str(0))) if os.path.isfile(os.path.join(test_dir, str(0), f))]\n",
        "\n",
        "  for f in train_csv_list:\n",
        "    epoch_num = int(f[-7:-4])\n",
        "    epoch_numbers.append(epoch_num)\n",
        "\n",
        "  for csv_train in train_csv_list:\n",
        "    df = pd.DataFrame()\n",
        "    for i in range(5):\n",
        "      curr_file = os.path.join(train_dir, str(i), csv_train)\n",
        "      if not os.path.isfile(curr_file):\n",
        "        continue\n",
        "      df_curr = pd.read_csv(curr_file)\n",
        "      df = pd.concat([df, df_curr])\n",
        "\n",
        "    label = df['label'].to_numpy()\n",
        "    model_score = df['model_score'].to_numpy()\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(label, model_score)\n",
        "\n",
        "    f_score_list = list()\n",
        "    for pre, rec in zip(precision, recall):\n",
        "      lower = pre + rec\n",
        "      if lower == 0.0:\n",
        "        lower = 0.00000001\n",
        "      \n",
        "      f_score_list.append(2 * (pre * rec) / lower)\n",
        "\n",
        "    f_score = max(f_score_list)\n",
        "\n",
        "    train_f_scores.append(f_score)\n",
        "  \n",
        "  highest_f_score = 0\n",
        "  highest_f_score_idx = 0\n",
        "\n",
        "  for csv_test, e in zip(test_csv_list, epoch_numbers):\n",
        "    df = pd.DataFrame()\n",
        "    for i in range(5):\n",
        "      curr_file = os.path.join(test_dir, str(i), csv_test)\n",
        "      df_curr = pd.read_csv(curr_file)\n",
        "      df = pd.concat([df, df_curr])\n",
        "\n",
        "    label = df['label'].to_numpy().astype(np.int8)\n",
        "    model_score = df['model_score'].to_numpy()\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(label, model_score)\n",
        "\n",
        "    f_score_list = list()\n",
        "    for pre, rec in zip(precision, recall):\n",
        "      lower = pre + rec\n",
        "      if lower == 0.0:\n",
        "        lower = 0.00000001\n",
        "      \n",
        "      f_score_list.append(2 * (pre * rec) / lower)\n",
        "\n",
        "    f_score = max(f_score_list)\n",
        "\n",
        "    if f_score > highest_f_score:\n",
        "      highest_f_score = f_score\n",
        "      highest_f_score_idx = e\n",
        "\n",
        "    test_f_scores.append(f_score)\n",
        "\n",
        "  teststr = f\"Highest Val Score: {str(highest_f_score)[0:5]} @ epoch {highest_f_score_idx}\"\n",
        "  \n",
        "\n",
        "  print(epoch_numbers)\n",
        "  plt.plot(epoch_numbers, train_f_scores, color = \"red\", label = \"Train\")\n",
        "  plt.plot(epoch_numbers, test_f_scores, color = \"blue\", label = \"Val\")\n",
        "  plt.legend(loc=\"upper left\")\n",
        "  plt.title(f'Run Name: {dir_name[:-1]}\\n{teststr}')\n",
        "  plt.ylabel('F-Score')\n",
        "  plt.xlabel('Epoch Number')\n",
        "  plt.savefig(os.path.join(dir_name, \"train_test_curve.png\"))\n",
        "  plt.save(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iASuQw9KtlDv"
      },
      "source": [
        "2. Creating a set of F-score curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3zep6y9t8le"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter('error')\n",
        "\n",
        "dir_name_list = glob(\"*/\")\n",
        "if os.path.isfile(\"results.zip\"):\n",
        "  dir_name_list.remove(\"results.zip\")\n",
        "\n",
        "for dir_name in dir_name_list:\n",
        "  train_dir = os.path.join(dir_name, \"train\")\n",
        "  test_dir = os.path.join(dir_name, \"test\")\n",
        "\n",
        "  train_csv_list = [f for f in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, f))]\n",
        "  test_csv_list = [f for f in os.listdir(test_dir) if os.path.isfile(os.path.join(test_dir, f))]\n",
        "    \n",
        "  #TEST JW\n",
        "  jw_test = list()\n",
        "  df = pd.read_csv(os.path.join(test_dir, test_csv_list[0]))\n",
        "  name1 = df['name1']\n",
        "  name2 = df['name2']\n",
        "  label = df['label']\n",
        "\n",
        "  for n1, n2 in zip(name1, name2):\n",
        "    if isinstance(n1, float) or isinstance(n2, float):\n",
        "      jw_test.append(0.8)\n",
        "      continue\n",
        "    dist = jw_dist.get_jaro_distance(n1, n2, winkler = True, scaling = 0.1)\n",
        "    jw_test.append(dist)\n",
        "\n",
        "  precision_jw, recall_jw, jw_thresholds = precision_recall_curve(label, jw_test)\n",
        "  f_score_jw_list = list()\n",
        "  for pre, rec in zip(precision_jw, recall_jw):\n",
        "    lower = pre + rec\n",
        "    if lower == 0.0:\n",
        "      lower = 0.00000001\n",
        "    \n",
        "    f_score_jw_list.append(2 * (pre * rec) / lower)\n",
        "\n",
        "  highest_f_score = 0\n",
        "  highest_f_score_idx = 0\n",
        "  highest_f_score_scores = None\n",
        "  highest_f_score_precision = None\n",
        "  highest_f_score_recall = None\n",
        "\n",
        "  for csv_test in test_csv_list:\n",
        "    for i in range(5):\n",
        "    curr_file = os.path.join(test_dir, csv_test)\n",
        "    df = pd.read_csv(curr_file)\n",
        "\n",
        "    label = df['label']\n",
        "    model_score = df['model_score']\n",
        "\n",
        "    epoch_num = int(curr_file[-7:-4])\n",
        "\n",
        "    df = df.to_numpy()\n",
        "\n",
        "    model_score = model_score.to_numpy()\n",
        "    label = label.to_numpy().astype(np.int8)\n",
        "\n",
        "    precision_mod, recall_mod, thresholds = precision_recall_curve(label, model_score)\n",
        "\n",
        "    f_score_test_list = list()\n",
        "    for pre, rec in zip(precision_mod, recall_mod):\n",
        "      lower = pre + rec\n",
        "      if lower == 0.0:\n",
        "        lower = 0.00000001\n",
        "      \n",
        "      f_score_test_list.append(2 * (pre * rec) / lower)\n",
        "\n",
        "    f_score = max(f_score_test_list)\n",
        "\n",
        "    if f_score > highest_f_score:\n",
        "      highest_f_score = f_score\n",
        "      highest_f_score_idx = epoch_num\n",
        "      highest_f_score_scores = f_score_test_list\n",
        "      highest_f_score_precision = precision_mod\n",
        "      highest_f_score_recall = recall_mod\n",
        "\n",
        "    auc_score = auc(recall_mod, precision_mod)\n",
        "\n",
        "    teststr = f\"Highest Test Score: {str(highest_f_score)[0:5]} @ epoch {highest_f_score_idx}\"\n",
        "    aucstr = f\"AUC: {str(auc_score)[0:7]}\"\n",
        "\n",
        "    save_dir = os.path.join(dir_name, \"f_curves\")\n",
        "    if not os.path.isdir(save_dir):\n",
        "      os.mkdir(save_dir)\n",
        "\n",
        "    plt.plot(highest_f_score_recall, highest_f_score_precision, color = \"lightcoral\", label = \"Sia (Best)\")\n",
        "    plt.plot(recall_mod, precision_mod, color = \"blue\", label = \"Sia\")\n",
        "    plt.plot(recall_jw, precision_jw, color = \"red\", label = \"JW\")\n",
        "    plt.xlim((-0.05, 1.05))\n",
        "    plt.ylim((-0.05, 1.05))\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.title(f'Run Name: {dir_name[:-1]}\\n{teststr}\\n{aucstr}')\n",
        "    plt.ylabel('F-Score')\n",
        "    plt.xlabel('Thresholds')\n",
        "    plt.savefig(os.path.join(save_dir, f\"curve{str(epoch_num).zfill(3)}.png\"))\n",
        "    plt.figure().clear()\n",
        "    plt.close()\n",
        "    plt.cla()\n",
        "    plt.clf()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "typRGEcht9DW"
      },
      "source": [
        "3. Creating gifs for the changing F-score curves over epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhMKkFcpfETw",
        "outputId": "c9c3b460-b1a4-44b7-9ce5-29b6818c2bdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/7Channel/siamese_vinden/results\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/7Channel/siamese_vinden/results\n",
        "warnings.simplefilter('error')\n",
        "\n",
        "'''\n",
        "dir_name_list = glob(\"*/\")\n",
        "dir_name_list = glob(\"*/\")\n",
        "if 'init_11_25/' in dir_name_list:\n",
        "  dir_name_list.remove('init_11_25/')\n",
        "'''\n",
        "dir_name_list = ['init_41_50/', ]\n",
        "\n",
        "for dir_name in dir_name_list:\n",
        "  train_dir = os.path.join(dir_name, \"train\")\n",
        "  test_dir = os.path.join(dir_name, \"test\")\n",
        "\n",
        "  # filepaths\n",
        "  fp_in = os.path.join(dir_name, \"f_curves\", \"curve*.png\")\n",
        "  fp_out = os.path.join(dir_name, \"F_curve.gif\")\n",
        "\n",
        "  # https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html#gif\n",
        "  img, *imgs = [Image.open(f) for f in sorted(glob.glob(fp_in))]\n",
        "  img.save(fp=fp_out, format='GIF', append_images=imgs,\n",
        "          save_all=True, duration=200, loop=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya6xViTZYTAk"
      },
      "source": [
        "4. Creating CSV files for positive, negative and jeremy for a initalized JSON file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckLO6_dTYZih",
        "outputId": "717b374a-d550-472e-98a5-8807b15ed761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/7Channel/siamese_vinden/results\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/7Channel/siamese_vinden/results\n",
        "f = open('../data/init_41_50.json', 'r')\n",
        " \n",
        "# returns JSON object as\n",
        "# a dictionary\n",
        "data = json.load(f)\n",
        "\n",
        "jer = np.concatenate(data['jeremy'])\n",
        "ran = np.concatenate(data['random'])\n",
        "\n",
        "def emb2str(emb):\n",
        "    word = \"\"\n",
        "    for char in emb:\n",
        "        char = char.item()\n",
        "        if char >= 30:\n",
        "            continue\n",
        "        word = word + chr(char + 97)\n",
        "    return word\n",
        "\n",
        "jer_list = pd.DataFrame(columns = [\"name_a\", \"name_b\"])\n",
        "ran_list = pd.DataFrame(columns = [\"name_a\", \"name_b\"])\n",
        "\n",
        "for name_a, name_b in jer:\n",
        "  name_a = emb2str(name_a)\n",
        "  name_b = emb2str(name_b)\n",
        "  jer_list = jer_list.append({\"name_a\": name_a, \"name_b\": name_b}, ignore_index = True)\n",
        "\n",
        "for name_a, name_b in ran:\n",
        "  name_a = emb2str(name_a)\n",
        "  name_b = emb2str(name_b)\n",
        "  ran_list = ran_list.append({\"name_a\": name_a, \"name_b\": name_b}, ignore_index = True)\n",
        "\n",
        "jer_list.to_csv(\"jeremy_pairs.csv\")\n",
        "ran_list.to_csv(\"random_pairs.csv\")\n",
        "\n",
        "# Closing file\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CreatePlotsSiamese.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
