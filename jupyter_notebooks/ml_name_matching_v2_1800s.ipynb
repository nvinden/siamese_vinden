{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "342cbba3",
      "metadata": {
        "id": "342cbba3"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from itertools import count\n",
        "import matplotlib.pyplot as plt\n",
        "from metaphone import doublemetaphone\n",
        "import pandas as pd\n",
        "from statistics import mean\n",
        "import textdistance\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_recall_curve, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import cross_val_predict, cross_validate, StratifiedKFold\n",
        "\n",
        "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
        "from matplotlib_venn import venn3, venn3_circles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9db0b999",
      "metadata": {
        "id": "9db0b999"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23bafc7a",
      "metadata": {
        "id": "23bafc7a"
      },
      "source": [
        "Load your folds in the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ebbde1d4",
      "metadata": {
        "id": "ebbde1d4"
      },
      "outputs": [],
      "source": [
        "dir_name = \"../results/gru_soundex\"\n",
        "\n",
        "folds = []\n",
        "\n",
        "for i in range(5):\n",
        "  test_csv = os.path.join(dir_name, f\"test_k{i}.csv\")\n",
        "  df = pd.read_csv(test_csv, usecols=[\"name1\", \"name2\", \"label\"])\n",
        "  df = df.astype({\"label\": bool, \"name1\": str, \"name2\": str})\n",
        "  df = df.rename(columns={\"name1\": \"name_a\", \"name2\": \"name_b\"})\n",
        "\n",
        "  folds.append(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5RLejLDZOqNu",
      "metadata": {
        "id": "5RLejLDZOqNu"
      },
      "source": [
        "Loads data from the 1871/1878 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aANB_WJIOpbw",
      "metadata": {
        "id": "aANB_WJIOpbw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6d0ea005",
      "metadata": {
        "id": "6d0ea005"
      },
      "source": [
        "Once your folds are loaded, the output of the following commands should look roughly like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fb7c5f53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb7c5f53",
        "outputId": "2c99136f-acff-4200-8dc8-d600f4bd987d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f6951839",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "f6951839",
        "outputId": "0e110149-d353-4c87-810a-6c5c275f81a8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name_a</th>\n",
              "      <th>name_b</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dessell</td>\n",
              "      <td>pessall</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ellgood</td>\n",
              "      <td>elwood</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ermann</td>\n",
              "      <td>erman</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>koland</td>\n",
              "      <td>nowland</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>radebach</td>\n",
              "      <td>rasbach</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>tildsley</td>\n",
              "      <td>bertini</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>rieck</td>\n",
              "      <td>riek</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>dippery</td>\n",
              "      <td>brohart</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>wipperman</td>\n",
              "      <td>wippermann</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14999</th>\n",
              "      <td>utteridge</td>\n",
              "      <td>uttridge</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          name_a      name_b  label\n",
              "0        dessell     pessall  False\n",
              "1        ellgood      elwood  False\n",
              "2         ermann       erman   True\n",
              "3         koland     nowland  False\n",
              "4       radebach     rasbach  False\n",
              "...          ...         ...    ...\n",
              "14995   tildsley     bertini  False\n",
              "14996      rieck        riek  False\n",
              "14997    dippery     brohart  False\n",
              "14998  wipperman  wippermann   True\n",
              "14999  utteridge    uttridge   True\n",
              "\n",
              "[15000 rows x 3 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folds[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5915958b",
      "metadata": {
        "id": "5915958b"
      },
      "source": [
        "# Generate Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e15e945c",
      "metadata": {
        "id": "e15e945c"
      },
      "outputs": [],
      "source": [
        "def compare_dm1(s1, s2):\n",
        "    return textdistance.levenshtein.normalized_similarity(doublemetaphone(s1)[0],doublemetaphone(s2)[0])\n",
        "\n",
        "def compare_dm2(s1, s2):\n",
        "    return textdistance.levenshtein.normalized_similarity(doublemetaphone(s1)[1],doublemetaphone(s2)[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4a12502d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a12502d",
        "outputId": "b2c1c04e-c782-403f-dfc8-0d1927f7fbcf"
      },
      "outputs": [],
      "source": [
        "from metaphone import doublemetaphone\n",
        "import jellyfish\n",
        "\n",
        "for pairs in folds:\n",
        "    pairs['levenshtein'] = [textdistance.levenshtein.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "    pairs['jaro'] = [textdistance.jaro.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "    pairs['jaro_winkler'] = [textdistance.jaro_winkler.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "    pairs['jaccard'] = [textdistance.jaccard.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "    pairs['sorensen_dice'] = [textdistance.sorensen_dice.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "    pairs['dm1'] = [compare_dm1(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "    pairs['dm2'] = [compare_dm2(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "\n",
        "    pairs['vowels_a'] = pairs['name_a'].apply(lambda x: sum(map(x.count, 'aeiou')))\n",
        "    pairs['vowels_b'] = pairs['name_b'].apply(lambda x: sum(map(x.count, 'aeiou')))\n",
        "    pairs['consonants_a'] = pairs['name_a'].str.len() - pairs['vowels_a']\n",
        "    pairs['consonants_b'] = pairs['name_b'].str.len() - pairs['vowels_b']\n",
        "    pairs['vowels'] = (pairs['vowels_a'] - pairs['vowels_b']).abs()\n",
        "    pairs['vowels'] = 1 - (pairs['vowels'] / pairs['vowels'].max())\n",
        "    pairs['consonants'] = (pairs['consonants_a'] - pairs['consonants_b']).abs()\n",
        "    pairs['consonants'] = 1 - (pairs['consonants'] / pairs['consonants'].max())\n",
        "    pairs['characters'] = (pairs['name_a'].str.len() - pairs['name_b'].str.len()).abs()\n",
        "    pairs['characters'] = 1 - (pairs['characters'] / pairs['characters'].max())\n",
        "\n",
        "    #Phonetic Component:\n",
        "    pairs[\"levenshtein_phonetic\"] = [textdistance.levenshtein.normalized_similarity(jellyfish.soundex(x), jellyfish.soundex(y)) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "    pairs[\"jw_phonetic\"] = [textdistance.jaro_winkler.normalized_similarity(jellyfish.soundex(x), jellyfish.soundex(y)) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "\n",
        "    pairs = pairs.drop(columns=['vowels_a', 'vowels_b', 'consonants_a', 'consonants_b'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bbf33c9",
      "metadata": {
        "id": "5bbf33c9"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24f81503",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bf5292a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "bf5292a5",
        "outputId": "85733dd8-dee5-4691-c1e8-e4abae31c570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       levenshtein      jaro  jaro_winkler   jaccard  sorensen_dice       dm1  \\\n",
            "0         0.714286  0.809524      0.809524  0.555556       0.714286  0.666667   \n",
            "1         0.714286  0.849206      0.879365  0.625000       0.769231  0.750000   \n",
            "2         0.833333  0.944444      0.966667  0.833333       0.909091  1.000000   \n",
            "3         0.714286  0.849206      0.849206  0.625000       0.769231  0.750000   \n",
            "4         0.750000  0.869048      0.895238  0.666667       0.800000  0.750000   \n",
            "...            ...       ...           ...       ...            ...       ...   \n",
            "14995     0.000000  0.511905      0.511905  0.250000       0.400000  0.200000   \n",
            "14996     0.800000  0.933333      0.953333  0.800000       0.888889  1.000000   \n",
            "14997     0.142857  0.428571      0.428571  0.076923       0.142857  0.200000   \n",
            "14998     0.900000  0.966667      0.980000  0.900000       0.947368  1.000000   \n",
            "14999     0.888889  0.962963      0.974074  0.888889       0.941176  1.000000   \n",
            "\n",
            "       dm2  vowels_a  vowels_b  consonants_a  consonants_b    vowels  \\\n",
            "0      1.0         2         2             5             5  1.000000   \n",
            "1      1.0         3         3             4             3  1.000000   \n",
            "2      1.0         2         2             4             3  1.000000   \n",
            "3      1.0         2         2             4             5  1.000000   \n",
            "4      1.0         3         2             5             5  0.833333   \n",
            "...    ...       ...       ...           ...           ...       ...   \n",
            "14995  1.0         2         3             6             4  0.833333   \n",
            "14996  1.0         2         2             3             2  1.000000   \n",
            "14997  1.0         2         2             5             5  1.000000   \n",
            "14998  1.0         3         3             6             7  1.000000   \n",
            "14999  1.0         4         3             5             5  0.833333   \n",
            "\n",
            "       consonants  characters  levenshtein_phonetic  jw_phonetic  \n",
            "0        1.000000    1.000000                  0.75     0.833333  \n",
            "1        0.923077    0.947368                  0.50     0.866667  \n",
            "2        0.923077    0.947368                  1.00     1.000000  \n",
            "3        0.923077    0.947368                  0.75     0.833333  \n",
            "4        1.000000    0.947368                  0.75     0.850000  \n",
            "...           ...         ...                   ...          ...  \n",
            "14995    0.846154    0.947368                  0.25     0.500000  \n",
            "14996    0.923077    0.947368                  1.00     1.000000  \n",
            "14997    1.000000    1.000000                  0.25     0.500000  \n",
            "14998    0.923077    0.947368                  1.00     1.000000  \n",
            "14999    1.000000    0.947368                  1.00     1.000000  \n",
            "\n",
            "[15000 rows x 16 columns]\n",
            "       levenshtein      jaro  jaro_winkler   jaccard  sorensen_dice       dm1  \\\n",
            "0         0.833333  0.888889      0.900000  0.714286       0.833333  0.750000   \n",
            "1         0.700000  0.825926      0.895556  0.583333       0.736842  0.666667   \n",
            "2         0.875000  0.916667      0.950000  0.777778       0.875000  1.000000   \n",
            "3         0.800000  0.854630      0.854630  0.727273       0.842105  0.800000   \n",
            "4         0.714286  0.849206      0.849206  0.857143       0.923077  0.333333   \n",
            "...            ...       ...           ...       ...            ...       ...   \n",
            "14995     0.125000  0.430556      0.430556  0.272727       0.428571  0.666667   \n",
            "14996     0.714286  0.896825      0.917460  0.857143       0.923077  0.750000   \n",
            "14997     0.000000  0.539683      0.539683  0.300000       0.461538  0.250000   \n",
            "14998     0.888889  0.879630      0.903704  0.888889       0.941176  1.000000   \n",
            "14999     0.857143  0.952381      0.971429  0.857143       0.923077  1.000000   \n",
            "\n",
            "            dm2  vowels_a  vowels_b  consonants_a  consonants_b    vowels  \\\n",
            "0      1.000000         3         2             3             4  0.833333   \n",
            "1      0.666667         3         3             7             6  1.000000   \n",
            "2      1.000000         2         3             6             5  0.833333   \n",
            "3      1.000000         3         3             6             7  1.000000   \n",
            "4      0.000000         2         2             4             5  1.000000   \n",
            "...         ...       ...       ...           ...           ...       ...   \n",
            "14995  1.000000         2         5             4             3  0.500000   \n",
            "14996  1.000000         3         3             4             3  1.000000   \n",
            "14997  1.000000         3         2             3             5  0.833333   \n",
            "14998  1.000000         5         4             4             4  0.833333   \n",
            "14999  1.000000         2         2             5             4  1.000000   \n",
            "\n",
            "       consonants  characters  levenshtein_phonetic  jw_phonetic  \n",
            "0           0.875         1.0                  0.50     0.850000  \n",
            "1           0.875         0.9                  0.75     0.866667  \n",
            "2           0.875         1.0                  1.00     1.000000  \n",
            "3           0.875         0.9                  0.75     0.833333  \n",
            "4           0.875         0.9                  0.50     0.666667  \n",
            "...           ...         ...                   ...          ...  \n",
            "14995       0.875         0.8                  0.50     0.666667  \n",
            "14996       0.875         0.9                  0.50     0.866667  \n",
            "14997       0.750         0.9                  0.25     0.500000  \n",
            "14998       1.000         0.9                  1.00     1.000000  \n",
            "14999       0.875         0.9                  1.00     1.000000  \n",
            "\n",
            "[15000 rows x 16 columns]\n",
            "       levenshtein      jaro  jaro_winkler   jaccard  sorensen_dice       dm1  \\\n",
            "0         0.714286  0.904762      0.923810  0.714286       0.833333  0.600000   \n",
            "1         0.800000  0.866667      0.906667  0.666667       0.800000  0.666667   \n",
            "2         0.888889  0.962963      0.977778  0.888889       0.941176  1.000000   \n",
            "3         0.714286  0.809524      0.809524  0.555556       0.714286  0.500000   \n",
            "4         0.714286  0.904762      0.942857  0.714286       0.833333  1.000000   \n",
            "...            ...       ...           ...       ...            ...       ...   \n",
            "14995     0.000000  0.000000      0.000000  0.071429       0.133333  0.000000   \n",
            "14996     0.750000  0.869048      0.869048  0.666667       0.800000  0.600000   \n",
            "14997     0.125000  0.550000      0.550000  0.181818       0.307692  0.000000   \n",
            "14998     0.857143  0.952381      0.971429  0.857143       0.923077  1.000000   \n",
            "14999     0.833333  0.888889      0.922222  0.714286       0.833333  1.000000   \n",
            "\n",
            "       dm2  vowels_a  vowels_b  consonants_a  consonants_b  vowels  \\\n",
            "0      1.0         2         2             3             5     1.0   \n",
            "1      0.0         1         1             4             4     1.0   \n",
            "2      1.0         4         3             5             5     0.8   \n",
            "3      1.0         2         2             5             5     1.0   \n",
            "4      1.0         2         2             3             5     1.0   \n",
            "...    ...       ...       ...           ...           ...     ...   \n",
            "14995  0.0         2         2             6             5     1.0   \n",
            "14996  1.0         3         3             4             5     1.0   \n",
            "14997  1.0         2         4             3             4     0.6   \n",
            "14998  1.0         2         1             5             5     0.8   \n",
            "14999  1.0         2         2             4             4     1.0   \n",
            "\n",
            "       consonants  characters  levenshtein_phonetic  jw_phonetic  \n",
            "0           0.750    0.818182                  0.25     0.500000  \n",
            "1           1.000    1.000000                  0.75     0.866667  \n",
            "2           1.000    0.909091                  1.00     1.000000  \n",
            "3           1.000    1.000000                  0.25     0.666667  \n",
            "4           0.750    0.818182                  1.00     1.000000  \n",
            "...           ...         ...                   ...          ...  \n",
            "14995       0.875    0.909091                  0.25     0.500000  \n",
            "14996       0.875    0.909091                  0.50     0.666667  \n",
            "14997       0.875    0.727273                  0.00     0.500000  \n",
            "14998       1.000    0.909091                  1.00     1.000000  \n",
            "14999       1.000    1.000000                  1.00     1.000000  \n",
            "\n",
            "[15000 rows x 16 columns]\n",
            "       levenshtein      jaro  jaro_winkler   jaccard  sorensen_dice       dm1  \\\n",
            "0         0.714286  0.809524      0.809524  0.555556       0.714286  0.666667   \n",
            "1         0.714286  0.742857      0.742857  0.555556       0.714286  0.500000   \n",
            "2         0.857143  0.952381      0.971429  0.857143       0.923077  1.000000   \n",
            "3         0.700000  0.825926      0.843333  0.583333       0.736842  0.800000   \n",
            "4         0.800000  0.933333      0.960000  0.800000       0.888889  0.666667   \n",
            "...            ...       ...           ...       ...            ...       ...   \n",
            "14995     0.000000  0.436508      0.436508  0.181818       0.307692  0.000000   \n",
            "14996     0.750000  0.869048      0.921429  0.666667       0.800000  0.800000   \n",
            "14997     0.000000  0.455556      0.455556  0.100000       0.181818  0.000000   \n",
            "14998     0.800000  0.896296      0.906667  0.727273       0.842105  0.833333   \n",
            "14999     0.875000  0.958333      0.975000  0.875000       0.933333  1.000000   \n",
            "\n",
            "            dm2  vowels_a  vowels_b  consonants_a  consonants_b  vowels  \\\n",
            "0      1.000000         2         2             5             5     1.0   \n",
            "1      1.000000         2         2             5             5     1.0   \n",
            "2      1.000000         2         2             5             4     1.0   \n",
            "3      1.000000         4         4             6             5     1.0   \n",
            "4      1.000000         2         2             2             3     1.0   \n",
            "...         ...       ...       ...           ...           ...     ...   \n",
            "14995  1.000000         3         3             4             3     1.0   \n",
            "14996  1.000000         2         3             5             5     0.8   \n",
            "14997  1.000000         2         1             4             4     0.8   \n",
            "14998  0.833333         3         3             7             6     1.0   \n",
            "14999  1.000000         2         2             6             5     1.0   \n",
            "\n",
            "       consonants  characters  levenshtein_phonetic  jw_phonetic  \n",
            "0             1.0    1.000000                  0.75     0.833333  \n",
            "1             1.0    1.000000                  0.25     0.666667  \n",
            "2             0.9    0.928571                  1.00     1.000000  \n",
            "3             0.9    0.928571                  1.00     1.000000  \n",
            "4             0.9    0.928571                  0.75     0.866667  \n",
            "...           ...         ...                   ...          ...  \n",
            "14995         0.9    0.928571                  0.00     0.500000  \n",
            "14996         1.0    0.928571                  0.75     0.883333  \n",
            "14997         1.0    0.928571                  0.25     0.500000  \n",
            "14998         0.9    0.928571                  0.50     0.850000  \n",
            "14999         0.9    0.928571                  1.00     1.000000  \n",
            "\n",
            "[15000 rows x 16 columns]\n",
            "       levenshtein      jaro  jaro_winkler   jaccard  sorensen_dice       dm1  \\\n",
            "0         0.875000  0.916667      0.925000  0.777778       0.875000  0.666667   \n",
            "1         0.714286  0.896825      0.927778  0.857143       0.923077  0.500000   \n",
            "2         0.900000  0.966667      0.980000  0.900000       0.947368  1.000000   \n",
            "3         0.833333  0.888889      0.922222  0.714286       0.833333  1.000000   \n",
            "4         0.714286  0.809524      0.809524  0.555556       0.714286  0.666667   \n",
            "...            ...       ...           ...       ...            ...       ...   \n",
            "14995     0.166667  0.455556      0.455556  0.100000       0.181818  0.000000   \n",
            "14996     0.833333  0.888889      0.888889  0.714286       0.833333  0.666667   \n",
            "14997     0.100000  0.566667      0.566667  0.166667       0.285714  0.142857   \n",
            "14998     0.875000  0.958333      0.975000  0.875000       0.933333  1.000000   \n",
            "14999     0.888889  0.884259      0.930556  0.800000       0.888889  1.000000   \n",
            "\n",
            "       dm2  vowels_a  vowels_b  consonants_a  consonants_b    vowels  \\\n",
            "0      1.0         2         2             6             6  1.000000   \n",
            "1      1.0         3         3             4             3  1.000000   \n",
            "2      1.0         2         2             7             8  1.000000   \n",
            "3      1.0         2         2             4             4  1.000000   \n",
            "4      1.0         2         2             5             5  1.000000   \n",
            "...    ...       ...       ...           ...           ...       ...   \n",
            "14995  1.0         4         2             1             4  0.666667   \n",
            "14996  1.0         2         2             4             4  1.000000   \n",
            "14997  1.0         2         3             2             7  0.833333   \n",
            "14998  1.0         1         1             6             7  1.000000   \n",
            "14999  1.0         3         3             6             6  1.000000   \n",
            "\n",
            "       consonants  characters  levenshtein_phonetic  jw_phonetic  \n",
            "0           1.000    1.000000                  0.50     0.850000  \n",
            "1           0.875    0.916667                  0.25     0.750000  \n",
            "2           0.875    0.916667                  1.00     1.000000  \n",
            "3           1.000    1.000000                  1.00     1.000000  \n",
            "4           1.000    1.000000                  0.75     0.833333  \n",
            "...           ...         ...                   ...          ...  \n",
            "14995       0.625    0.916667                  0.00     0.000000  \n",
            "14996       1.000    1.000000                  0.75     0.833333  \n",
            "14997       0.375    0.500000                  0.00     0.500000  \n",
            "14998       0.875    0.916667                  1.00     1.000000  \n",
            "14999       1.000    1.000000                  1.00     1.000000  \n",
            "\n",
            "[15000 rows x 16 columns]\n",
            "{'test_precision': 0.9079234897392723, 'test_recall': 0.92276, 'f1_score': 0.9152725540740583, 'tp': 4613.8, 'tn': 9532, 'fp': 468, 'fn': 386.2}\n",
            "CPU times: user 31.8 s, sys: 266 ms, total: 32 s\n",
            "Wall time: 36.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "scores = defaultdict(list)\n",
        "y_prob = []\n",
        "name_a = []\n",
        "name_b = []\n",
        "labels = []\n",
        "\n",
        "rf_y_pred = []\n",
        "\n",
        "rf_models = []\n",
        "\n",
        "for test_fold_index in range(len(folds)):\n",
        "    val_fold_index = test_fold_index - 1 if test_fold_index - 1 >= 0 else len(folds) - 1\n",
        "\n",
        "    X_train = pd.DataFrame()\n",
        "    y_train = pd.Series(dtype=bool)\n",
        "    for fold_index in range(len(folds)):\n",
        "        if fold_index != test_fold_index and fold_index != val_fold_index:\n",
        "            X_train = pd.concat([X_train, folds[fold_index].drop(columns=['name_a', 'name_b', 'label'])])\n",
        "            y_train = pd.concat([y_train, folds[fold_index]['label']])\n",
        "    name_a = name_a + folds[test_fold_index][\"name_a\"].values.tolist()\n",
        "    name_b = name_b + folds[test_fold_index][\"name_b\"].values.tolist()\n",
        "    X_test = folds[test_fold_index].drop(columns=['name_a', 'name_b', 'label'])\n",
        "    y_test = folds[test_fold_index]['label']\n",
        "    \n",
        "    clf = RandomForestClassifier(random_state=0)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(X_test)\n",
        "    \n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    rf_y_pred += np.array(y_pred).tolist()\n",
        "\n",
        "    scores['test_precision'].append(precision_score(y_test, y_pred))\n",
        "    scores['test_recall'].append(recall_score(y_test, y_pred))\n",
        "    scores['f1_score'].append(f1_score(y_test, y_pred))\n",
        "\n",
        "    yt = np.array(y_test)\n",
        "    yp = np.array(y_pred)\n",
        "\n",
        "    to_labels = yt.astype(int).tolist()\n",
        "    labels = labels + to_labels\n",
        "\n",
        "    scores['tp'].append(np.count_nonzero(yt & yp))\n",
        "    scores['tn'].append(np.count_nonzero(np.logical_not(yt) & np.logical_not(yp)))\n",
        "    scores['fp'].append(np.count_nonzero(np.logical_not(yt) & yp))\n",
        "    scores['fn'].append(np.count_nonzero(yt & np.logical_not(yp)))\n",
        "\n",
        "    y_prob += [x[1] for x in clf.predict_proba(X_test)]\n",
        "\n",
        "    rf_models.append(clf)\n",
        "\n",
        "print({k: mean(v) for k, v in scores.items()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "c7df4288",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_14501/1234879118.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  pairs['levenshtein'] = [textdistance.levenshtein.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
            "/tmp/ipykernel_14501/1234879118.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  pairs['jaro'] = [textdistance.jaro.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
            "/tmp/ipykernel_14501/1234879118.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  pairs['jaro_winkler'] = [textdistance.jaro_winkler.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
            "/tmp/ipykernel_14501/1234879118.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  pairs['jaccard'] = [textdistance.jaccard.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
            "/tmp/ipykernel_14501/1234879118.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  pairs['sorensen_dice'] = [textdistance.sorensen_dice.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(os.path.join(dir_name, \"DL_results_full.csv\"))\n",
        "\n",
        "pairs = df[[\"name_a\", \"name_b\"]]\n",
        "\n",
        "pairs['levenshtein'] = [textdistance.levenshtein.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "pairs['jaro'] = [textdistance.jaro.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "pairs['jaro_winkler'] = [textdistance.jaro_winkler.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "pairs['jaccard'] = [textdistance.jaccard.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "pairs['sorensen_dice'] = [textdistance.sorensen_dice.normalized_similarity(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "pairs['dm1'] = [compare_dm1(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "pairs['dm2'] = [compare_dm2(x, y) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "\n",
        "pairs['vowels_a'] = pairs['name_a'].apply(lambda x: sum(map(x.count, 'aeiou')))\n",
        "pairs['vowels_b'] = pairs['name_b'].apply(lambda x: sum(map(x.count, 'aeiou')))\n",
        "pairs['consonants_a'] = pairs['name_a'].str.len() - pairs['vowels_a']\n",
        "pairs['consonants_b'] = pairs['name_b'].str.len() - pairs['vowels_b']\n",
        "pairs['vowels'] = (pairs['vowels_a'] - pairs['vowels_b']).abs()\n",
        "pairs['vowels'] = 1 - (pairs['vowels'] / pairs['vowels'].max())\n",
        "pairs['consonants'] = (pairs['consonants_a'] - pairs['consonants_b']).abs()\n",
        "pairs['consonants'] = 1 - (pairs['consonants'] / pairs['consonants'].max())\n",
        "pairs['characters'] = (pairs['name_a'].str.len() - pairs['name_b'].str.len()).abs()\n",
        "pairs['characters'] = 1 - (pairs['characters'] / pairs['characters'].max())\n",
        "\n",
        "#Phonetic Component:\n",
        "pairs[\"levenshtein_phonetic\"] = [textdistance.levenshtein.normalized_similarity(jellyfish.soundex(x), jellyfish.soundex(y)) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "pairs[\"jw_phonetic\"] = [textdistance.jaro_winkler.normalized_similarity(jellyfish.soundex(x), jellyfish.soundex(y)) for x, y in pairs[['name_a', 'name_b']].itertuples(index=False)]\n",
        "\n",
        "all_preds = []\n",
        "\n",
        "for model in rf_models:\n",
        "    X_test = pairs.drop(columns=['name_a', 'name_b'])\n",
        "\n",
        "    pred = model.predict(X_test)\n",
        "\n",
        "    all_preds.append(np.array([int(i) for i in pred]))\n",
        "\n",
        "sums = sum(all_preds)\n",
        "final_pred = [1.0 if number >= 3 else 0.0 for number in sums]\n",
        "\n",
        "df = df[[\"name_a\", \"name_b\"]]\n",
        "df[\"pred\"] = final_pred\n",
        "\n",
        "df.to_csv(os.path.join(dir_name, \"RF_results_full.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e91dfb0",
      "metadata": {},
      "source": [
        "## Creating Venn Diagram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "a4b4ea42",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(os.path.join(dir_name, \"DL_results_full.csv\"))\n",
        "\n",
        "yp = np.array(df['pred'], dtype = int)\n",
        "yt = np.ones(yp.shape, dtype = int)\n",
        "\n",
        "df['tp'] = yt & yp\n",
        "df['tn'] = np.array(np.logical_not(yt) & np.logical_not(yp), dtype = int)\n",
        "df['fp'] = np.logical_not(yt) & yp\n",
        "df['fn'] = yt & np.logical_not(yp)\n",
        "\n",
        "df.to_csv(os.path.join(dir_name, \"DL_results_full.csv\"))\n",
        "\n",
        "df = pd.read_csv(os.path.join(dir_name, \"RF_results_full.csv\"))\n",
        "\n",
        "yp = np.array(df['pred'], dtype = int)\n",
        "yt = np.ones(yp.shape, dtype = int)\n",
        "\n",
        "df['tp'] = yt & yp\n",
        "df['tn'] = np.array(np.logical_not(yt) & np.logical_not(yp), dtype = int)\n",
        "df['fp'] = np.logical_not(yt) & yp\n",
        "df['fn'] = yt & np.logical_not(yp)\n",
        "\n",
        "df.to_csv(os.path.join(dir_name, \"RF_results_full.csv\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "7b72c438",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nvinden/anaconda3/envs/siamese/lib/python3.9/site-packages/matplotlib_venn/_venn2.py:50: UserWarning: Both circles have zero area\n",
            "  warnings.warn(\"Both circles have zero area\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_rf = pd.read_csv(os.path.join(dir_name, \"RF_results_full.csv\"))\n",
        "df_dl = pd.read_csv(os.path.join(dir_name, \"DL_results_full.csv\"))\n",
        "\n",
        "rf_tp = df_rf.loc[df_rf['tp'] == 1].to_dict('records')\n",
        "rf_tn = df_rf.loc[df_rf['tn'] == 1].to_dict('records')\n",
        "rf_fp = df_rf.loc[df_rf['fp'] == 1].to_dict('records')\n",
        "rf_fn = df_rf.loc[df_rf['fn'] == 1].to_dict('records')\n",
        "\n",
        "#print(rf_tp)\n",
        "\n",
        "rf_tp_names = {str(row['name_a']) + \"_\" + str(row['name_b']) for row in rf_tp}\n",
        "rf_tn_names = {str(row['name_a']) + \"_\" + str(row['name_b']) for row in rf_tn}\n",
        "rf_fp_names = {str(row['name_a']) + \"_\" + str(row['name_b']) for row in rf_fp}\n",
        "rf_fn_names = {str(row['name_a']) + \"_\" + str(row['name_b']) for row in rf_fn}\n",
        "\n",
        "dl_tp = df_dl.loc[df_dl['tp'] == 1].to_dict('records')\n",
        "dl_tn = df_dl.loc[df_dl['tn'] == 1].to_dict('records')\n",
        "dl_fp = df_dl.loc[df_dl['fp'] == 1].to_dict('records')\n",
        "dl_fn = df_dl.loc[df_dl['fn'] == 1].to_dict('records')\n",
        "\n",
        "dl_tp_names = {str(row['name_a']) + \"_\" + str(row['name_b']) for row in dl_tp}\n",
        "dl_tn_names = {str(row['name_a']) + \"_\" + str(row['name_b']) for row in dl_tn}\n",
        "dl_fp_names = {str(row['name_a']) + \"_\" + str(row['name_b']) for row in dl_fp}\n",
        "dl_fn_names = {str(row['name_a']) + \"_\" + str(row['name_b']) for row in dl_fn}\n",
        "\n",
        "total_tp = rf_tp_names.union(dl_tp_names)\n",
        "total_fp = rf_fp_names.union(dl_tn_names)\n",
        "total_tn = rf_tn_names.union(dl_fp_names)\n",
        "total_fn = rf_tn_names.union(dl_fn_names)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(f'True Positives')\n",
        "venn2(\n",
        "    (dl_tp_names, rf_tp_names),\n",
        "    set_labels = ('Deep Learning', 'Random Forest'),\n",
        "    subset_label_formatter=lambda x: f'{x:,}\\n{x / len(total_tp) * 100:.1f}%'\n",
        ")\n",
        "plt.savefig(f\"{dir_name}/TP_venn_1800.jpg\")\n",
        "plt.clf()\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(f'False Positives')\n",
        "venn2(\n",
        "    (dl_fp_names, rf_fp_names),\n",
        "    set_labels = ('Deep Learning', 'Random Forest'),\n",
        "    subset_label_formatter=lambda x: f'{x:,}\\n{x / len(total_tp) * 100:.1f}%'\n",
        ")\n",
        "plt.savefig(f\"{dir_name}/FP_venn_1800.jpg\")\n",
        "plt.clf()\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(f'True Negatives')\n",
        "venn2(\n",
        "    (dl_tn_names, rf_tn_names),\n",
        "    set_labels = ('Deep Learning', 'Random Forest'),\n",
        "    subset_label_formatter=lambda x: f'{x:,}\\n{x / len(total_tp) * 100:.1f}%'\n",
        ")\n",
        "plt.savefig(f\"{dir_name}/TN_venn_1800.jpg\")\n",
        "plt.clf()\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(f'False Negatives')\n",
        "venn2(\n",
        "    (dl_fn_names, rf_fn_names),\n",
        "    set_labels = ('Deep Learning', 'Random Forest'),\n",
        "    subset_label_formatter=lambda x: f'{x:,}\\n{x / len(total_tp) * 100:.1f}%'\n",
        ")\n",
        "plt.savefig(f\"{dir_name}/FN_venn_1800.jpg\")\n",
        "plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "287b78db",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['pred'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_14501/1803843155.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_dl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_dl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4904\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4905\u001b[0m         \"\"\"\n\u001b[0;32m-> 4906\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4907\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4908\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['pred'] not found in axis\""
          ]
        }
      ],
      "source": [
        "#Creating the csv for R analysis on vowels and etc\n",
        "\n",
        "df_rf = pd.read_csv(os.path.join(dir_name, \"RF_results_full.csv\"))\n",
        "df_dl = pd.read_csv(os.path.join(dir_name, \"DL_results_full.csv\"))\n",
        "\n",
        "df_rf['label'] = df_rf['pred']\n",
        "df_dl['label'] = df_dl['pred']\n",
        "\n",
        "df_rf = df_rf.drop([\"pred\"])\n",
        "df_dl = df_dl.drop([\"pred\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_rf[\"N_N\"] = df_rf[\"name_a\"] + \"_\" + df_rf[\"name_b\"]\n",
        "df_dl[\"N_N\"] = df_dl[\"name_a\"] + \"_\" + df_dl[\"name_b\"]\n",
        "\n",
        "fp_rf = df_rf.loc[df_rf['fp'] == 1]\n",
        "fn_rf = df_rf.loc[df_rf['fn'] == 1]\n",
        "\n",
        "fp_dl = df_dl.loc[df_dl['fp'] == 1]\n",
        "fn_dl = df_dl.loc[df_dl['fn'] == 1]\n",
        "\n",
        "fp_rf = fp_rf.drop(columns = [\"label\", \"tp\", \"tn\", \"score\", \"fn\", \"Unnamed: 0\"])\n",
        "fn_rf = fn_rf.drop(columns = [\"label\", \"tp\", \"tn\", \"fp\", \"score\", \"Unnamed: 0\"])\n",
        "fp_dl = fp_dl.drop(columns = [\"label\", \"tp\", \"tn\", \"score\", \"fn\", \"Unnamed: 0\"])\n",
        "fn_dl = fn_dl.drop(columns = [\"label\", \"tp\", \"tn\", \"fp\", \"score\", \"Unnamed: 0\"])\n",
        "\n",
        "fp_rf = fp_rf.rename(columns = {\"fp\": \"RF\"})\n",
        "fn_rf = fn_rf.rename(columns = {\"fn\": \"RF\"})\n",
        "fp_dl = fp_dl.rename(columns = {\"fp\": \"DL\"})\n",
        "fn_dl = fn_dl.rename(columns = {\"fn\": \"DL\"})\n",
        "\n",
        "fp = pd.merge(fp_rf, fp_dl[[\"name_a\", \"name_b\", \"DL\"]], on = [\"name_a\", \"name_b\"], how = \"outer\")\n",
        "fp = fp.fillna(0)\n",
        "\n",
        "'''\n",
        "fp.loc[fp['RF'] == 1, 'cat'] = 'RF'\n",
        "fp.loc[fp['DL'] == 1, 'cat'] = 'DL'\n",
        "fp.loc[(fp['DL'] == 1) & (fp['RF'] == 1), 'cat'] = 'BOTH'\n",
        "\n",
        "fp = fp.to_dict('records')\n",
        "for row in fp:\n",
        "    row[\"length_diff\"] = abs(len(row[\"name_a\"]) - len(row[\"name_b\"]))\n",
        "    row[\"length_avg\"] = (len(row[\"name_a\"]) + len(row[\"name_b\"])) / 2\n",
        "\n",
        "    name_a_vowels = 0\n",
        "    for let in row[\"name_a\"]:\n",
        "        if let in \"aeiou\":\n",
        "            name_a_vowels += 1\n",
        "    name_a_const = len(row[\"name_a\"]) - name_a_vowels\n",
        "\n",
        "    name_b_vowels = 0\n",
        "    for let in row[\"name_b\"]:\n",
        "        if let in \"aeiou\":\n",
        "            name_b_vowels += 1\n",
        "    name_b_const = len(row[\"name_b\"]) - name_b_vowels\n",
        "\n",
        "    row[\"vowel_diff\"] = abs(name_a_vowels - name_b_vowels)\n",
        "    row[\"vowel_avg\"] = abs(name_a_vowels + name_b_vowels) / 2\n",
        "\n",
        "    row[\"const_diff\"] = abs(name_a_const - name_b_const)\n",
        "    row[\"const_avg\"] = abs(name_a_const + name_b_const) / 2\n",
        "\n",
        "    row[\"subset\"] = 1 if (row[\"name_a\"] in row[\"name_b\"]) or (row[\"name_b\"] in row[\"name_a\"]) else 0\n",
        "    row[\"copy\"] = 1 if (row[\"name_a\"] == row[\"name_b\"]) and row[\"subset\"] != 1 else 0\n",
        "\n",
        "fp = pd.DataFrame(fp)\n",
        "fp.to_csv(os.path.join(dir_name, \"fp_master.csv\"))\n",
        "'''\n",
        "\n",
        "fn = pd.merge(fn_rf, fn_dl[[\"name_a\", \"name_b\", \"DL\"]], on = [\"name_a\", \"name_b\"], how = \"outer\")\n",
        "fn = fn.fillna(0)\n",
        "\n",
        "fn.loc[fn['RF'] == 1, 'cat'] = 'RF'\n",
        "fn.loc[fn['DL'] == 1, 'cat'] = 'DL'\n",
        "fn.loc[(fn['DL'] == 1) & (fn['RF'] == 1), 'cat'] = 'BOTH'\n",
        "\n",
        "fn = fn.to_dict('records')\n",
        "for row in fn:\n",
        "    row[\"length_diff\"] = abs(len(row[\"name_a\"]) - len(row[\"name_b\"]))\n",
        "    row[\"length_avg\"] = (len(row[\"name_a\"]) + len(row[\"name_b\"])) / 2\n",
        "\n",
        "    name_a_vowels = 0\n",
        "    for let in row[\"name_a\"]:\n",
        "        if let in \"aeiou\":\n",
        "            name_a_vowels += 1\n",
        "    name_a_const = len(row[\"name_a\"]) - name_a_vowels\n",
        "\n",
        "    name_b_vowels = 0\n",
        "    for let in row[\"name_b\"]:\n",
        "        if let in \"aeiou\":\n",
        "            name_b_vowels += 1\n",
        "    name_b_const = len(row[\"name_b\"]) - name_b_vowels\n",
        "\n",
        "    row[\"vowel_diff\"] = abs(name_a_vowels - name_b_vowels)\n",
        "    row[\"vowel_avg\"] = abs(name_a_vowels + name_b_vowels) / 2\n",
        "\n",
        "    row[\"const_diff\"] = abs(name_a_const - name_b_const)\n",
        "    row[\"const_avg\"] = abs(name_a_const + name_b_const) / 2\n",
        "\n",
        "    row[\"subset\"] = 1 if (row[\"name_a\"] in row[\"name_b\"]) or (row[\"name_b\"] in row[\"name_a\"]) else 0\n",
        "    row[\"copy\"] = 1 if (row[\"name_a\"] == row[\"name_b\"]) and row[\"subset\"] != 1 else 0\n",
        "\n",
        "fn = pd.DataFrame(fn)\n",
        "\n",
        "fn.to_csv(os.path.join(dir_name, \"fn_master_1800s.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "20b58295",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ntn.loc[tn[\\'RF\\'] == 1, \\'cat\\'] = \\'RF\\'\\ntn.loc[tn[\\'DL\\'] == 1, \\'cat\\'] = \\'DL\\'\\ntn.loc[(tn[\\'DL\\'] == 1) & (tn[\\'RF\\'] == 1), \\'cat\\'] = \\'BOTH\\'\\n\\ntn = tn.to_dict(\\'records\\')\\nfor row in tn:\\n    row[\"length_diff\"] = abs(len(row[\"name_a\"]) - len(row[\"name_b\"]))\\n    row[\"length_avg\"] = (len(row[\"name_a\"]) + len(row[\"name_b\"])) / 2\\n\\n    name_a_vowels = 0\\n    for let in row[\"name_a\"]:\\n        if let in \"aeiou\":\\n            name_a_vowels += 1\\n    name_a_const = len(row[\"name_a\"]) - name_a_vowels\\n\\n    name_b_vowels = 0\\n    for let in row[\"name_b\"]:\\n        if let in \"aeiou\":\\n            name_b_vowels += 1\\n    name_b_const = len(row[\"name_b\"]) - name_b_vowels\\n\\n    row[\"vowel_diff\"] = abs(name_a_vowels - name_b_vowels)\\n    row[\"vowel_avg\"] = abs(name_a_vowels + name_b_vowels) / 2\\n\\n    row[\"const_diff\"] = abs(name_a_const - name_b_const)\\n    row[\"const_avg\"] = abs(name_a_const + name_b_const) / 2\\n\\n    row[\"subset\"] = 1 if (row[\"name_a\"] in row[\"name_b\"]) or (row[\"name_b\"] in row[\"name_a\"]) else 0\\n    row[\"copy\"] = 1 if (row[\"name_a\"] == row[\"name_b\"]) and row[\"subset\"] != 1 else 0\\n\\ntn = pd.DataFrame(tn)\\n\\ntn.to_csv(os.path.join(dir_name, \"tn_master.csv\"))\\n'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Creating the csv for R analysis on vowels and etc\n",
        "\n",
        "df_rf = pd.read_csv(os.path.join(dir_name, \"RF_results.csv\"))\n",
        "df_dl = pd.read_csv(os.path.join(dir_name, \"DL_results.csv\"))\n",
        "\n",
        "df_rf[\"N_N\"] = df_rf[\"name_a\"] + \"_\" + df_rf[\"name_b\"]\n",
        "df_dl[\"N_N\"] = df_dl[\"name_a\"] + \"_\" + df_dl[\"name_b\"]\n",
        "\n",
        "tp_rf = df_rf.loc[df_rf['tp'] == 1]\n",
        "tn_rf = df_rf.loc[df_rf['tn'] == 1]\n",
        "\n",
        "tp_dl = df_dl.loc[df_dl['tp'] == 1]\n",
        "tn_dl = df_dl.loc[df_dl['tn'] == 1]\n",
        "\n",
        "tp_rf = tp_rf.drop(columns = [\"label\", \"fp\", \"fn\", \"score\", \"tn\", \"Unnamed: 0\"])\n",
        "tn_rf = tn_rf.drop(columns = [\"label\", \"fp\", \"fn\", \"tp\", \"score\", \"Unnamed: 0\"])\n",
        "tp_dl = tp_dl.drop(columns = [\"label\", \"fp\", \"fn\", \"score\", \"tn\", \"Unnamed: 0\"])\n",
        "tn_dl = tn_dl.drop(columns = [\"label\", \"fp\", \"fn\", \"tp\", \"score\", \"Unnamed: 0\"])\n",
        "\n",
        "tp_rf = tp_rf.rename(columns = {\"tp\": \"RF\"})\n",
        "tn_rf = tn_rf.rename(columns = {\"tn\": \"RF\"})\n",
        "tp_dl = tp_dl.rename(columns = {\"tp\": \"DL\"})\n",
        "tn_dl = tn_dl.rename(columns = {\"tn\": \"DL\"})\n",
        "\n",
        "tp = pd.merge(tp_rf, tp_dl[[\"name_a\", \"name_b\", \"DL\"]], on = [\"name_a\", \"name_b\"], how = \"outer\")\n",
        "tp = tp.fillna(0)\n",
        "\n",
        "tp.loc[tp['RF'] == 1, 'cat'] = 'RF'\n",
        "tp.loc[tp['DL'] == 1, 'cat'] = 'DL'\n",
        "tp.loc[(tp['DL'] == 1) & (tp['RF'] == 1), 'cat'] = 'BOTH'\n",
        "\n",
        "tp = tp.to_dict('records')\n",
        "#print(tp)\n",
        "for row in tp:\n",
        "    if row[\"name_a\"] == \"nau\" or row[\"name_b\"] == \"nau\":\n",
        "        continue\n",
        "    row[\"length_diff\"] = abs(len(row[\"name_a\"]) - len(row[\"name_b\"]))\n",
        "    row[\"length_avg\"] = (len(row[\"name_a\"]) + len(row[\"name_b\"])) / 2\n",
        "\n",
        "    name_a_vowels = 0\n",
        "    for let in row[\"name_a\"]:\n",
        "        if let in \"aeiou\":\n",
        "            name_a_vowels += 1\n",
        "    name_a_const = len(row[\"name_a\"]) - name_a_vowels\n",
        "\n",
        "    name_b_vowels = 0\n",
        "    for let in row[\"name_b\"]:\n",
        "        if let in \"aeiou\":\n",
        "            name_b_vowels += 1\n",
        "    name_b_const = len(row[\"name_b\"]) - name_b_vowels\n",
        "\n",
        "    row[\"vowel_diff\"] = abs(name_a_vowels - name_b_vowels)\n",
        "    row[\"vowel_avg\"] = abs(name_a_vowels + name_b_vowels) / 2\n",
        "\n",
        "    row[\"const_diff\"] = abs(name_a_const - name_b_const)\n",
        "    row[\"const_avg\"] = abs(name_a_const + name_b_const) / 2\n",
        "\n",
        "    row[\"subset\"] = 1 if (row[\"name_a\"] in row[\"name_b\"]) or (row[\"name_b\"] in row[\"name_a\"]) else 0\n",
        "    row[\"copy\"] = 1 if (row[\"name_a\"] == row[\"name_b\"]) and row[\"subset\"] != 1 else 0\n",
        "\n",
        "tp = pd.DataFrame(tp)\n",
        "tp.to_csv(os.path.join(dir_name, \"tp_master_1800s.csv\"))\n",
        "\n",
        "tn = pd.merge(tn_rf, tn_dl[[\"name_a\", \"name_b\", \"DL\"]], on = [\"name_a\", \"name_b\"], how = \"outer\")\n",
        "tn = tn.fillna(0)\n",
        "\n",
        "'''\n",
        "tn.loc[tn['RF'] == 1, 'cat'] = 'RF'\n",
        "tn.loc[tn['DL'] == 1, 'cat'] = 'DL'\n",
        "tn.loc[(tn['DL'] == 1) & (tn['RF'] == 1), 'cat'] = 'BOTH'\n",
        "\n",
        "tn = tn.to_dict('records')\n",
        "for row in tn:\n",
        "    row[\"length_diff\"] = abs(len(row[\"name_a\"]) - len(row[\"name_b\"]))\n",
        "    row[\"length_avg\"] = (len(row[\"name_a\"]) + len(row[\"name_b\"])) / 2\n",
        "\n",
        "    name_a_vowels = 0\n",
        "    for let in row[\"name_a\"]:\n",
        "        if let in \"aeiou\":\n",
        "            name_a_vowels += 1\n",
        "    name_a_const = len(row[\"name_a\"]) - name_a_vowels\n",
        "\n",
        "    name_b_vowels = 0\n",
        "    for let in row[\"name_b\"]:\n",
        "        if let in \"aeiou\":\n",
        "            name_b_vowels += 1\n",
        "    name_b_const = len(row[\"name_b\"]) - name_b_vowels\n",
        "\n",
        "    row[\"vowel_diff\"] = abs(name_a_vowels - name_b_vowels)\n",
        "    row[\"vowel_avg\"] = abs(name_a_vowels + name_b_vowels) / 2\n",
        "\n",
        "    row[\"const_diff\"] = abs(name_a_const - name_b_const)\n",
        "    row[\"const_avg\"] = abs(name_a_const + name_b_const) / 2\n",
        "\n",
        "    row[\"subset\"] = 1 if (row[\"name_a\"] in row[\"name_b\"]) or (row[\"name_b\"] in row[\"name_a\"]) else 0\n",
        "    row[\"copy\"] = 1 if (row[\"name_a\"] == row[\"name_b\"]) and row[\"subset\"] != 1 else 0\n",
        "\n",
        "tn = pd.DataFrame(tn)\n",
        "\n",
        "tn.to_csv(os.path.join(dir_name, \"tn_master.csv\"))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2f40e62c",
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../results/gru_soundex/fp_master.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_2628/2936206147.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Do analysis on some of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fp_master.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'length_diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpercent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/gru_soundex/fp_master.csv'"
          ]
        }
      ],
      "source": [
        "#Do analysis on some of the data\n",
        "fp = pd.read_csv(os.path.join(dir_name, \"fp_master.csv\"))\n",
        "\n",
        "val = fp.loc[fp['cat'] == 'DL']['length_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Length Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"1.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff LENGTH\")\n",
        "val = fp.loc[fp['cat'] == 'BOTH']['length_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Length Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"2.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff LENGTH\")\n",
        "val = fp.loc[fp['cat'] == 'RF']['length_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Length Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"3.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "\n",
        "print(\"DL diff VOWEL\")\n",
        "val = fp.loc[fp['cat'] == 'DL']['vowel_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Vowel Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"4.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff VOWEL\")\n",
        "val = fp.loc[fp['cat'] == 'BOTH']['vowel_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Vowel Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"5.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff VOWEL\")\n",
        "val = fp.loc[fp['cat'] == 'RF']['vowel_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Vowel Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"6.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "print(\"DL diff CONST\")\n",
        "val = fp.loc[fp['cat'] == 'DL']['const_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Const Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"7.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff CONST\")\n",
        "val = fp.loc[fp['cat'] == 'BOTH']['const_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Const Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"8.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff CONST\")\n",
        "val = fp.loc[fp['cat'] == 'RF']['const_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Const Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"9.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "\n",
        "print(\"DL diff SUBSET\")\n",
        "val = fp.loc[fp['cat'] == 'DL']['subset']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"10.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff SUBSET\")\n",
        "val = fp.loc[fp['cat'] == 'BOTH']['subset']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"11.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff SUBSET\")\n",
        "val = fp.loc[fp['cat'] == 'RF']['subset']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Subset Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"12.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"DL diff COPY\")\n",
        "val = fp.loc[fp['cat'] == 'DL']['copy']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"13.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff COPY\")\n",
        "val = fp.loc[fp['cat'] == 'BOTH']['copy']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"14.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff COPY\")\n",
        "val = fp.loc[fp['cat'] == 'RF']['copy']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"15.jpg\"))\n",
        "plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbed5d8b",
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../results/edit_emb20_lay8/fn_master.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_6520/4004835995.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Do analysis on some of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fn_master.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'length_diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpercent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/edit_emb20_lay8/fn_master.csv'"
          ]
        }
      ],
      "source": [
        "#Do analysis on some of the data\n",
        "fn = pd.read_csv(os.path.join(dir_name, \"fn_master.csv\"))\n",
        "\n",
        "val = fn.loc[fn['cat'] == 'DL']['length_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Length Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_1.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff LENGTH\")\n",
        "val = fn.loc[fn['cat'] == 'BOTH']['length_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Length Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_2.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff LENGTH\")\n",
        "val = fn.loc[fn['cat'] == 'RF']['length_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Length Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_3.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "\n",
        "print(\"DL diff VOWEL\")\n",
        "val = fn.loc[fn['cat'] == 'DL']['vowel_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Vowel Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_4.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff VOWEL\")\n",
        "val = fn.loc[fn['cat'] == 'BOTH']['vowel_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Vowel Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_5.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff VOWEL\")\n",
        "val = fn.loc[fn['cat'] == 'RF']['vowel_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Vowel Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_6.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "print(\"DL diff CONST\")\n",
        "val = fn.loc[fn['cat'] == 'DL']['const_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Const Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_7.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff CONST\")\n",
        "val = fn.loc[fn['cat'] == 'BOTH']['const_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Const Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_8.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff CONST\")\n",
        "val = fn.loc[fn['cat'] == 'RF']['const_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Const Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_9.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "\n",
        "print(\"DL diff SUBSET\")\n",
        "val = fn.loc[fn['cat'] == 'DL']['subset']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_10.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff SUBSET\")\n",
        "val = fn.loc[fn['cat'] == 'BOTH']['subset']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_11.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff SUBSET\")\n",
        "val = fn.loc[fn['cat'] == 'RF']['subset']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_12.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"DL diff COPY\")\n",
        "val = fn.loc[fn['cat'] == 'DL']['copy']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_13.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff COPY\")\n",
        "val = fn.loc[fn['cat'] == 'BOTH']['copy']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_14.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff COPY\")\n",
        "val = fn.loc[fn['cat'] == 'RF']['copy']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "print(percent)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_15.jpg\"))\n",
        "plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b6930745",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_14508/2902242104.py:5: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only\n",
            "  percent = val.value_counts().sort_index(0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOTH diff LENGTH\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_14508/2902242104.py:16: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only\n",
            "  percent = val.value_counts().sort_index(0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF diff LENGTH\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_14508/2902242104.py:27: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only\n",
            "  percent = val.value_counts().sort_index(0)\n",
            "/tmp/ipykernel_14508/2902242104.py:109: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only\n",
            "  percent = val.value_counts().sort_index(0)\n",
            "/tmp/ipykernel_14508/2902242104.py:120: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only\n",
            "  percent = val.value_counts().sort_index(0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DL diff SUBSET\n",
            "BOTH diff SUBSET\n",
            "RF diff SUBSET\n",
            "DL diff COPY\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_14508/2902242104.py:131: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only\n",
            "  percent = val.value_counts().sort_index(0)\n",
            "/tmp/ipykernel_14508/2902242104.py:145: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only\n",
            "  percent = val.value_counts().sort_index(0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOTH diff COPY\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_14508/2902242104.py:156: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only\n",
            "  percent = val.value_counts().sort_index(0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF diff COPY\n",
            "0.0    2041\n",
            "Name: copy, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_14508/2902242104.py:167: FutureWarning: In a future version of pandas all arguments of Series.sort_index will be keyword-only\n",
            "  percent = val.value_counts().sort_index(0)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Do analysis on some of the data\n",
        "tp = pd.read_csv(os.path.join(dir_name, \"tp_master.csv\"))\n",
        "\n",
        "val = tp.loc[tp['cat'] == 'DL']['length_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Length Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tp_1_DL_LENGTH.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff LENGTH\")\n",
        "val = tp.loc[tp['cat'] == 'BOTH']['length_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Length Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tp_2_BOTH_LENGTH.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff LENGTH\")\n",
        "val = tp.loc[tp['cat'] == 'RF']['length_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Length Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tp_3_RF_LENGTH.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "'''\n",
        "print(\"DL diff VOWEL\")\n",
        "val = tp.loc[tp['cat'] == 'DL']['vowel_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Vowel Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_4.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff VOWEL\")\n",
        "val = tp.loc[tp['cat'] == 'BOTH']['vowel_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Vowel Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_5.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff VOWEL\")\n",
        "val = tp.loc[ftpn['cat'] == 'RF']['vowel_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Vowel Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_6.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "print(\"DL diff CONST\")\n",
        "val = tp.loc[tp['cat'] == 'DL']['const_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Const Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_7.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff CONST\")\n",
        "val = fn.loc[fn['cat'] == 'BOTH']['const_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Const Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_8.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff CONST\")\n",
        "val = fn.loc[fn['cat'] == 'RF']['const_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Const Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_9.jpg\"))\n",
        "plt.clf()\n",
        "'''\n",
        "\n",
        "\n",
        "print(\"DL diff SUBSET\")\n",
        "val = tp.loc[tp['cat'] == 'DL']['subset']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tp_10_ML_Subset.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff SUBSET\")\n",
        "val = tp.loc[tp['cat'] == 'BOTH']['subset']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tp_11_BOTH_Subset.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff SUBSET\")\n",
        "val = tp.loc[tp['cat'] == 'RF']['subset']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tp_12_DL_Subset.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"DL diff COPY\")\n",
        "val = tp.loc[tp['cat'] == 'DL']['copy']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tp_13_DL_Copy.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff COPY\")\n",
        "val = tp.loc[tp['cat'] == 'BOTH']['copy']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tp_14_BOTH_Copy.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff COPY\")\n",
        "val = tp.loc[tp['cat'] == 'RF']['copy']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "print(percent)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tp_15_RF_Copy.jpg\"))\n",
        "plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c91155aa",
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../results/edit_emb20_lay8/tn_master.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_14508/3580888757.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Do analysis on some of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tn_master.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'length_diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpercent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/siamese/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/edit_emb20_lay8/tn_master.csv'"
          ]
        }
      ],
      "source": [
        "#Do analysis on some of the data\n",
        "tn = pd.read_csv(os.path.join(dir_name, \"tn_master.csv\"))\n",
        "\n",
        "val = tn.loc[tn['cat'] == 'DL']['length_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Length Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tn_1_DL_LENGTH.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff LENGTH\")\n",
        "val = tn.loc[tn['cat'] == 'BOTH']['length_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Length Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tn_2_BOTH_LENGTH.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff LENGTH\")\n",
        "val = tn.loc[tn['cat'] == 'RF']['length_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Length Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tn_3_RF_LENGTH.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "'''\n",
        "print(\"DL diff VOWEL\")\n",
        "val = tp.loc[tp['cat'] == 'DL']['vowel_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Vowel Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_4.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff VOWEL\")\n",
        "val = tp.loc[tp['cat'] == 'BOTH']['vowel_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Vowel Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_5.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff VOWEL\")\n",
        "val = tp.loc[ftpn['cat'] == 'RF']['vowel_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Vowel Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_6.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "print(\"DL diff CONST\")\n",
        "val = tp.loc[tp['cat'] == 'DL']['const_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Const Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_7.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff CONST\")\n",
        "val = fn.loc[fn['cat'] == 'BOTH']['const_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Const Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_8.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff CONST\")\n",
        "val = fn.loc[fn['cat'] == 'RF']['const_diff']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Const Difference\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"fn_9.jpg\"))\n",
        "plt.clf()\n",
        "'''\n",
        "\n",
        "\n",
        "print(\"DL diff SUBSET\")\n",
        "val = tn.loc[tn['cat'] == 'DL']['subset']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tn_10_ML_Subset.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff SUBSET\")\n",
        "val = tn.loc[tn['cat'] == 'BOTH']['subset']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tn_11_BOTH_Subset.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff SUBSET\")\n",
        "val = tn.loc[tn['cat'] == 'RF']['subset']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tn_12_DL_Subset.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"DL diff COPY\")\n",
        "val = tn.loc[tn['cat'] == 'DL']['copy']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"DL Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tn_13_DL_Copy.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"BOTH diff COPY\")\n",
        "val = tn.loc[tn['cat'] == 'BOTH']['copy']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"BOTH Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tn_14_BOTH_Copy.jpg\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"RF diff COPY\")\n",
        "val = tn.loc[tn['cat'] == 'RF']['copy']\n",
        "percent = val.value_counts().sort_index(0)\n",
        "print(percent)\n",
        "percent = np.array(percent)\n",
        "index = np.array([str(i) for i in range(len(percent))])\n",
        "plt.pie(percent, labels = index)\n",
        "plt.suptitle(\"RF Copy Proportion\")\n",
        "plt.title(\"MEAN \" + str(mean(val))[0:5])\n",
        "plt.savefig(os.path.join(dir_name, \"r_charts\", \"tn_15_RF_Copy.jpg\"))\n",
        "plt.clf()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d75b5703",
      "metadata": {},
      "source": [
        "## Precision Recall Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b3f104",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "e1b3f104",
        "outputId": "9ba88324-3370-4cb8-9e84-07f6241c4624"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa151272910>]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcEUlEQVR4nO3deZRU9Z3+8fdDd0OjbCqNgywBFVSi4NIi7mLUgCRhYjaXxJPFMETNMplfjiaTScafo9mOZsaExBBjEk9mwiTRKImoUeOWqNEmAoqItqjQEqFRQVxYGj6/P25B+tcWdDXUrdvV93mdU6druVU8Fzj19N2+X0UEZmaWX72yDmBmZtlyEZiZ5ZyLwMws51wEZmY55yIwM8u52qwDdNXgwYNj1KhRWccwM6sq8+fPXxMRDcVeq7oiGDVqFE1NTVnHMDOrKpJe2NFr3jVkZpZzLgIzs5xzEZiZ5ZyLwMws51wEZmY5l1oRSLpe0mpJT+zgdUm6RlKzpEWSjkwri5mZ7ViaWwQ/A6bs5PWpwJjCbQbwwxSzmJnZDqR2HUFE3C9p1E4WmQ7cEMk42A9LGiRpaET8LY08S19az62LVqbx0WY9n8T4YQOR4KSxDdTVeK9yT5LlBWXDgBXtHrcUnntbEUiaQbLVwMiRI3fpD2te/Trfu6d5l95rlmfFpiw564hh/Ou0Q9inX5/KB7Kyy7IIVOS5orPkRMRsYDZAY2PjLs2kM238UKaNn7YrbzXLtQ2bt/DMqtcB+PrcJ/jr8rXc9NiL3PTYiwBMPfQf+O5HDqe+ribLmLYbsty+awFGtHs8HPC+G7Nupr6uhsOGD+Sw4QO56cLjeeaKqXz/3CO2v37bEy9x8L/dzopX3swwpe2OLItgLnB+4eyhScC6tI4PmFn51NX04j3j9+P5b05jyf+dwjv22QOAE799Dy+t25BxOtsVaZ4++kvgIeAgSS2SPiVppqSZhUXmAcuAZuDHwIVpZTGzdPTtXcN9X5rM+ybsB8Ckb9zNlfOWZJzKuirNs4bO6eT1AC5K6883s8q55pwj2LNPLb98ZDmz71/GKWMbOO7AwVnHshL5HDAzK4tvnHUYs85Nrgv9beFAslUHF4GZlc208UPpXduLX89vIYqdd2rdkovAzMrqkKEDABj95XmsXu+Dx9XARWBmZXXDJyduvz/xirszTGKlchGYWVkN7FvHc984k7H79gPg6VXrM05knXERmFnZSeKbHxgPwBnfvT/jNNYZF4GZpeLIkXttv//KG5syTGKdcRGYWWq++5EJANz+xEsZJ7GdcRGYWWqmHjoUgK/89nGu/sPSjNPYjrgIzCw19XU1XHNOMkDdNX9sZsPmLRknsmJcBGaWqvdN2I/PvWsMAN/74zMZp7FiXARmlrqLJh8AwKx7nmXtmz5w3N24CMwsdX1qazhnYjK74Hfu8LGC7sZFYGYV8Y2zDgPgv/+yPOMk1pGLwMwq5oxx+wLw0z8/l3ESa89FYGYVc/VHDgfgst89yRsb27INY9u5CMysYvr1qeWY0XsD8Ojzr2ScxrZxEZhZRX112jgAHl7mIuguXARmVlFjCqOSLmt9PeMkto2LwMwqqr6uhsNHDOIPT65i61bPYtYduAjMrOL27FMDQNMLr2acxMBFYGYZ+OLpBwFwxbwlGScxcBGYWQbGDx8IwMIVa3nkOR80zpqLwMwqrq6mFz8870gAPvyjhzJOYy4CM8vE1MOGbr/vi8uy5SIws8xc/o+HAvDAM2syTpJvLgIzy8wRIwYBcMmNi7INknMuAjPLzKHDBjJp/71Z99ZmNm/ZmnWc3HIRmFmmGt+RjD10mye4z4yLwMwy9ckTRgNw019bMk6SXy4CM8vU3nv2BuDepa0ZJ8mvVItA0hRJSyU1S7q0yOsDJf1O0kJJiyV9Is08Zta9eWjqbKRWBJJqgFnAVGAccI6kcR0Wuwh4MiImAKcAV0nqnVYmM+ue/nfGJACWv/xmxknyKc0tgolAc0Qsi4hNwBxgeodlAugvSUA/4BXAV5aY5cwBQ5Khqa/6gye2z0KaRTAMWNHucUvhufa+DxwCrAQeBz4fEW87h0zSDElNkppaW70f0ayn2XuPZEfAynUbaPNppBWXZhGoyHMdBx9/N7AA2A84HPi+pAFve1PE7IhojIjGhoaGcuc0s4z16iUumXIwAD9+wBPbV1qaRdACjGj3eDjJb/7tfQK4KRLNwHPAwSlmMrNu6oITk9NIv3X7U6x5fWPGafIlzSJ4FBgjaXThAPDZwNwOyywH3gUgaV/gIGBZipnMrJuqq+nFx48bBcAlv/GQE5WUWhFERBtwMXAHsAT4VUQsljRT0szCYpcDx0l6HLgbuCQiPPqUWU59/b3JiYV/al5DhKexrJTaND88IuYB8zo8d227+yuBM9LMYGbVQxKnHbIvdy1Zxb/PXcxl0w/NOlIu+MpiM+tWrjwr+fL/+UMvsHr9hozT5IOLwMy6lSH96/mX08cC8D9/WZ5xmnxwEZhZt/ORo5MTDn/d5IHoKsFFYGbdzpAB9Zw4ZjAvrn2L+S94/KG0uQjMrFv6cGOyVfCBHz7Elq0+gyhNLgIz65beO2E/Dhs2EIA/PrU64zQ9m4vAzLqt6z9+NACfvqEp4yQ9m4vAzLqthv59tt9fvHJdhkl6NheBmXVrN37mWACmXfMnmlevzzhNz+QiMLNu7ah37M2YwnwFp119f8ZpeiYXgZl1e3d84SQmDE8OHN/jA8dl5yIws26vVy9x5VmHAckw1VZeLgIzqwrv3C/ZInjqpfXcON9XHJeTi8DMqsbvP3sCAD9+wNOWlJOLwMyqxqHDBjKwbx1PvbTe8xWUkYvAzKrK0aP2BmD+C69mnKTncBGYWVW5aPIBAHz15ifY6jGIysJFYGZV5cDCNQVPvbSellffyjhNz+AiMLOq0r++jtkfOwqAy299MuM0PYOLwMyqzkljGwC488lVtG3ZmnGa6uciMLOqU19Xw8ePGwXAx37ySLZhegAXgZlVpUumHAzAQ8tezjhJ9XMRmFlV6tu7hosnHwjAedc9nHGa6uYiMLOqNePk/QH4c7O3CnaHi8DMqtaA+jpmnpxcV3D3klUZp6leLgIzq2rvfue+ACxYsTbbIFXMRWBmVW3bqKQekXTXuQjMrKr1ru3FgPpaVq7bwMa2LVnHqUouAjOrel84bSwAB331dp5Z5XmNu8pFYGZV79xjRm6/f/p3Pa9xV6VaBJKmSFoqqVnSpTtY5hRJCyQtlnRfmnnMrGeqr6vh2SvPZOLoZIjqe5Z6XuOuSK0IJNUAs4CpwDjgHEnjOiwzCPgB8L6IeCfwobTymFnPVtNLXDo1udr4tsf/lnGa6pLmFsFEoDkilkXEJmAOML3DMucCN0XEcoCIcI2b2S47cuReANyyYKXnKuiCNItgGLCi3eOWwnPtjQX2knSvpPmSzi/2QZJmSGqS1NTa2ppSXDPrCU4cM5iNbVs9V0EXlFQEko6XdKekpyUtk/ScpM5mj1aR5zpWdC1wFDANeDfwb5LGvu1NEbMjojEiGhsaGkqJbGY5de7E5MDxrd49VLJStwh+AlwNnAAcDTQWfu5MCzCi3ePhwMoiy9weEW9ExBrgfmBCiZnMzN7m+DGDAfjFwy9knKR6lFoE6yLitohYHREvb7t18p5HgTGSRkvqDZwNzO2wzC3AiZJqJe0BHAMs6dIamJm1M6C+jtGD9+TFtW9xy4IXs45TFUotgnskfUfSsZKO3Hbb2Rsiog24GLiD5Mv9VxGxWNJMSTMLyywBbgcWAY8A10XEE7u8NmZmwBXvPxSAy3/v3ytLUVvicscUfja2ey6AU3f2poiYB8zr8Ny1HR5/B/hOiTnMzDp13AHJ7qE1r2/koWdf5tgD9sk4UfdW0hZBREwucttpCZiZZemXn54EwK+aVnSypJV61tBASVdvO4VT0lWSBqYdzsxsV23bCvjtYy/6moJOlHqM4HpgPfDhwu014KdphTIzK4fTDknmKrjqzqUZJ+neSi2CAyLi64WrhJdFxGXA/mkGMzPbXbPOO4Letb2Ydc+zRHirYEdKLYK3JJ2w7YGk4wFftmdm3Vqf2hrOK4xM+tRLHp56R0otgs8AsyQ9L+kF4PvAzPRimZmVxzGjk2MFDz7rCe53pNSzhhZExARgPHBYRBwREQvTjWZmtvuOHDkIgFsXdRzYwLbZ6XUEkj4aEb+Q9MUOzwMQEVenmM3MbLcNGVDPvgP68Nfla9mweQv1dTVZR+p2Otsi2LPws/8ObmZm3d7UQ4cC8GtfU1DUTrcIIuJHhZ+XVSaOmVn5/fPpY/nZg89z55LVfHTSO7bv1bBEqReUfVvSAEl1ku6WtEbSR9MOZ2ZWDgPqk99573+6lTH/elvGabqfUs8aOiMiXgPeQzJ09FjgS6mlMjMrI0k89OVkVJy2rcH8F17NOFH3UmoR1BV+ngn8MiJeSSmPmVkqhg7sy80XHQ/A06t8TUF7pRbB7yQ9RTL66N2SGoAN6cUyMyu/A4f0A2DOI8szTtK9lHodwaXAsUBjRGwG3uDtE9GbmXVr/fokxwoWtqzjpr+2ZJym+9hpEUg6tfDzLGAyML1wfwpwXPrxzMzK66efSGbZ/eKvFrL2zU0Zp+keOtsiOLnw871Fbu9JMZeZWSomHzSEaYcl1xXc93Rrxmm6B1XbiHyNjY3R1NSUdQwzq2Kt6zdy9BV30b++lsf//d1Zx6kISfMjorHYa6VeR3ClpEHtHu8l6T/KlM/MrKIa+vdhv4H1rN/QxvRZf846TuZKPWtoakSs3fYgIl4lOZXUzKwq3XLxCdT2EgtXrOW3j+X7wHGpRVAjqc+2B5L6An12sryZWbfW0L8P937pFAB+9uAL2YbJ2E7HGmrnFyTXD/wUCOCTwM9TS2VmVgHD99qDg/+hP3W98j32UElFEBHflrQIOA0QcHlE3JFqMjOzChi+V1/uWrI66xiZKnWLAGAJ0BYRd0naQ1L/iPB12mZW1frUJvMTrFz7FvsN6ptxmmyUetbQp4HfAD8qPDUMuDmlTGZmFXP6uH0BWPfW5oyTZKfUg8UXAccDrwFExDPAkLRCmZlVyoC+yY6RjW1bM06SnVKLYGNEbL8WW1ItyUFjM7Oq1rsm2TV039L8XmVcahHcJ+krQF9JpwO/Bn6XXiwzs8oYufceAHz3rqfZlNOtglKL4BKgFXgc+CdgHvDVtEKZmVXKyH324OSxDQAsbFmbbZiMdHrWkKRewKKIOBT4cfqRzMwq67OnHsh9T7eyYfOWrKNkotMtgojYCiyUNLICeczMKq6uJvkq9K6hnRsKLC5MXD93262zN0maImmppGZJl+5kuaMlbZH0wVKDm5mVS+/a5Kvw6VWvZ5wkG6VeUHZZVz9YUg0wCzidZML7RyXNjYgniyz3LcBXKptZJgb0TaZl/9btTzFmSD9OK1xbkBedzVBWL+kLwIeAg4E/R8R9226dfPZEoDkilhVOPZ1D8ektPwvcCOT7Gm8zy8ywQX35r7MPB+CCG/I330lnu4Z+TjJh/ePAVOCqLnz2MGBFu8cthee2kzQMeD9w7c4+SNIMSU2Smlpb83uur5mlZ/rhw9h/8J4AXPjf8zNOU1mdFcG4iPhoRPwI+CBwYhc+u9hwfh0vQvtP4JKI2Omh+oiYHRGNEdHY0NDQhQhmZqX7yceT+YwXrliXcZLK6qwItg++ERFtXfzsFmBEu8fDgZUdlmkE5kh6nqRofiDpH7v455iZlcXowXty7jEjczfcRGdFMEHSa4XbemD8tvuSXuvkvY8CYySNltQbOBv4/840iojRETEqIkaRDGp3YUTcvGurYma2++pra1jz+kauuPVJVr+2Ies4FbHTIoiImogYULj1j4jadvcHdPLeNuBikrOBlgC/iojFkmZKmlm+VTAzK5+Txg5mSP8+/PiB55h45d1Zx6kIRVTX2HGNjY3R1JS/o/pmVlkTr7iL1es3svBrZzBwj7qs4+w2SfMjorHYa6VeUGZmlisXnnIAAE+s7PkHjl0EZmZFjB8xCIDNW3r+gWMXgZlZEb0L4w9t3lJdu893hYvAzKyIbQPRvbGxq2fOVx8XgZlZEX3rkpnLvvC/C7jg549mnCZdLgIzsyJG7N2Xqz40AYC7lqzu0XMVuAjMzIqQxAeOGs7Mk5Ozhz4/57GME6XHRWBmthMXTU6K4I7Fq3huzRsZp0mHi8DMbCf619dx8eQDAXhm1fqM06TDRWBm1olp44cCsGVrzzyV1EVgZtaJuppkVP3NLgIzs3yq7ZV8Vbb10KuMXQRmZp2o6ZVsEbT10KuMXQRmZp3oXZt8VV7++yc56vI7Wb9hcyfvqC4uAjOzTgzp34fPnnogCF5+YxOz7nk260hl5SIwM+uEJP7ljIN46MvvAuDepaszTlReLgIzsxL161PLsfvvw1Mv9azrCVwEZmZdcPjIQQBc8POeM1Oii8DMrAu2zVy2qGVttkHKyEVgZtYF/evr+EjjCHpJWUcpGxeBmVnOuQjMzHLORWBmlnMuAjOznHMRmJnlnIvAzCznXARmZrugbetWmle/3iMGoHMRmJl1UZ+6Xqx5fROnXX0fx1x5N5urfJ4CF4GZWRd97l1j+N45RzBhxCDe3LSFi//nr1lH2i0uAjOzLhrcrw/vnbAfN3xyIgB3LF7FdQ8syzjVrku1CCRNkbRUUrOkS4u8fp6kRYXbg5ImpJnHzKycBvatY86MSQD8x61L+Oh1fyGi+mYxS60IJNUAs4CpwDjgHEnjOiz2HHByRIwHLgdmp5XHzCwNk/bfhz/880kA/Kl5DT/98/PZBtoFaW4RTASaI2JZRGwC5gDT2y8QEQ9GxKuFhw8Dw1PMY2aWirH79qfpq6cBsGWrtwjaGwasaPe4pfDcjnwKuK3YC5JmSGqS1NTa2lrGiGZm5VFfV5N1hF2WZhEUG6O1aFVKmkxSBJcUez0iZkdEY0Q0NjQ0lDGimVl5RfGvuW6tNsXPbgFGtHs8HFjZcSFJ44HrgKkR8XKKeczMUrPtN98qPFac6hbBo8AYSaMl9QbOBua2X0DSSOAm4GMR8XSKWczMUrVtnpoq7IH0tggiok3SxcAdQA1wfUQsljSz8Pq1wNeAfYAfKPlbbIuIxrQymZmlRUX3hleHNHcNERHzgHkdnru23f0LgAvSzGBmVkneNWRmllN/3zVUfU3gIjAzKyNvEZiZ5ZSq9xCBi8DMrByq+WCxi8DMrIw86JyZWU5tP1hcfT3gIjAzK4ftVxZnmmLXuAjMzMpAVXy02EVgZlZG3jVkZpZTf981VH1N4CIwMysDHyw2M8s5HyMwMzPAZw2ZmVkV7htyEZiZlYnkLQIzs1yr1qMELgIzszKRVI17hlwEZmbl5OsIzMxyTFTlsWIXgZlZufhgsZlZzlXr5DQuAjOzcpF3DZmZ5Z4PFpuZ5ZigKg8SuAjMzMqkWsedcxGYmZWJUDVuELgIzMzKRYKowqPFtVkHMDPrSVav38jCFWtT+eyG/n3Yb1Dfsn+ui8DMrEz26F3LLQtWcsuClal8/syTD+DSqQeX/XNdBGZmZTJnxiSWv/JGap8/cu89U/lcF4GZWZkcOKQfBw7pl3WMLkv1YLGkKZKWSmqWdGmR1yXpmsLriyQdmWYeMzN7u9SKQFINMAuYCowDzpE0rsNiU4ExhdsM4Idp5TEzs+LS3CKYCDRHxLKI2ATMAaZ3WGY6cEMkHgYGSRqaYiYzM+sgzSIYBqxo97il8FxXl0HSDElNkppaW1vLHtTMLM/SLIJiF1t3vNKilGWIiNkR0RgRjQ0NDWUJZ2ZmiTSLoAUY0e7xcKDjybWlLGNmZilKswgeBcZIGi2pN3A2MLfDMnOB8wtnD00C1kXE31LMZGZmHaR2HUFEtEm6GLgDqAGuj4jFkmYWXr8WmAecCTQDbwKfSCuPmZkVl+oFZRExj+TLvv1z17a7H8BFaWYwM7Od8+ijZmY55yIwM8s5F4GZWc65CMzMck7VNpuOpFbghV18+2BgTRnjVAOvcz54nfNhd9b5HRFR9IrcqiuC3SGpKSIas85RSV7nfPA650Na6+xdQ2ZmOeciMDPLubwVweysA2TA65wPXud8SGWdc3WMwMzM3i5vWwRmZtaBi8DMLOd6ZBFImiJpqaRmSZcWeV2Srim8vkjSkVnkLKcS1vm8wroukvSgpAlZ5Cynzta53XJHS9oi6YOVzJeGUtZZ0imSFkhaLOm+SmcstxL+bw+U9DtJCwvrXNWjGEu6XtJqSU/s4PXyf39FRI+6kQx5/SywP9AbWAiM67DMmcBtJDOkTQL+knXuCqzzccBehftT87DO7Zb7I8kouB/MOncF/p0HAU8CIwuPh2SduwLr/BXgW4X7DcArQO+ss+/GOp8EHAk8sYPXy/791RO3CCYCzRGxLCI2AXOA6R2WmQ7cEImHgUGShlY6aBl1us4R8WBEvFp4+DDJbHDVrJR/Z4DPAjcCqysZLiWlrPO5wE0RsRwgIqp9vUtZ5wD6SxLQj6QI2iobs3wi4n6SddiRsn9/9cQiGAasaPe4pfBcV5epJl1dn0+R/EZRzTpdZ0nDgPcD19IzlPLvPBbYS9K9kuZLOr9i6dJRyjp/HziEZJrbx4HPR8TWysTLRNm/v1KdmCYjKvJcx3NkS1mmmpS8PpImkxTBCakmSl8p6/yfwCURsSX5ZbHqlbLOtcBRwLuAvsBDkh6OiKfTDpeSUtb53cAC4FTgAOBOSQ9ExGspZ8tK2b+/emIRtAAj2j0eTvKbQleXqSYlrY+k8cB1wNSIeLlC2dJSyjo3AnMKJTAYOFNSW0TcXJGE5Vfq/+01EfEG8Iak+4EJQLUWQSnr/Angm5HsQG+W9BxwMPBIZSJWXNm/v3rirqFHgTGSRkvqDZwNzO2wzFzg/MLR90nAuoj4W6WDllGn6yxpJHAT8LEq/u2wvU7XOSJGR8SoiBgF/Aa4sIpLAEr7v30LcKKkWkl7AMcASyqcs5xKWeflJFtASNoXOAhYVtGUlVX2768et0UQEW2SLgbuIDnj4PqIWCxpZuH1a0nOIDkTaAbeJPmNomqVuM5fA/YBflD4DbktqnjkxhLXuUcpZZ0jYomk24FFwFbguogoehpiNSjx3/ly4GeSHifZbXJJRFTt8NSSfgmcAgyW1AJ8HaiD9L6/PMSEmVnO9cRdQ2Zm1gUuAjOznHMRmJnlnIvAzCznXARmZjnnIjArojBa6QJJTxRGthxU5s9/XtLgwv3Xy/nZZl3lIjAr7q2IODwiDiUZAOyirAOZpcVFYNa5hygM6iXpAEm3FwZ0e0DSwYXn95X028KY+AslHVd4/ubCsoslzchwHcx2qMddWWxWTpJqSIYv+EnhqdnAzIh4RtIxwA9IBju7BrgvIt5feE+/wvKfjIhXJPUFHpV0Yw8Y58l6GBeBWXF9JS0ARgHzSUa07Ecywc+v241m2qfw81TgfICI2AKsKzz/OUnvL9wfAYwBXATWrbgIzIp7KyIOlzQQ+D3JMYKfAWsj4vBSPkDSKcBpwLER8aake4H6NMKa7Q4fIzDbiYhYB3wO+D/AW8Bzkj4E2+eO3Tb3893AZwrP10gaAAwEXi2UwMEk0wqadTsuArNORMRjJHPlng2cB3xK0kJgMX+fNvHzwOTCCJjzgXcCtwO1khaRjJD5cKWzm5XCo4+ameWctwjMzHLORWBmlnMuAjOznHMRmJnlnIvAzCznXARmZjnnIjAzy7n/B1JGBx15syvdAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.xlim((-0.05, 1.05))\n",
        "plt.ylim((-0.05, 1.05))\n",
        "precision, recall, _ = precision_recall_curve(pd.concat([fold['label'] for fold in folds]), y_prob)\n",
        "plt.step(recall, precision, where='post')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ml_name_matching_v2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "da916d797f95354a64649ce6624e60c5b4fdae02478f80dc3ee76903e7f64fe6"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('siamese')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
